{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset to dataframe\n",
    "\n",
    "Note that the dataset might be coming from BigQuery or from a query on the local database (created from the SE Data Dump). The two data sources should be interchangeable in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_FILE = \"saved_dataset.csv\"      # The file name of the saved dataset (saved on / loaded from local disk)\n",
    "cwd = Path().absolute()                 # Current working directory (note: possibly different from execution directory)\n",
    "\n",
    "# Load a saved copy of the dataset from local disk (if it exists)\n",
    "try:\n",
    "    dataset_path = os.path.join(cwd, DATASET_FILE)\n",
    "    results = pd.read_csv(dataset_path)\n",
    "    results = results.astype({\"creation_date\": \"datetime64[ns]\"})\n",
    "    print(\"Saved copy of dataset loaded from local disk.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Saved dataset not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cull / filter dataset\n",
    "\n",
    "For the demo we're just arbitrarily culling the size of the dataset to make it more manageable, but you could also filter for other reasons such as focusing on a specific tag, or sampling based on answer and/or question scores.\n",
    "\n",
    "A pandas dataframe can be sampled either:\n",
    "* Using a fractional value: e.g., ``.sample(frac=0.01)`` will result in a number of samples equivalent to 1% of the dataset.\n",
    "* Using an integer value: e.g., ``.sample(n=1000)`` will result in 1000 samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in currently selected filtered dataset: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75793</th>\n",
       "      <td>73545119</td>\n",
       "      <td>Unzip .zip File without Writing to Disc from R...</td>\n",
       "      <td>&lt;p&gt;Let me preface by stating that I' somewhat ...</td>\n",
       "      <td>73545325</td>\n",
       "      <td>60</td>\n",
       "      <td>c#|asp.net|api</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Assuming you actually have a &lt;code&gt;.zip&lt;/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151748</th>\n",
       "      <td>70934250</td>\n",
       "      <td>All self-hosted agents cannot connect to devop...</td>\n",
       "      <td>&lt;p&gt;All of our self-hosted agents cannot connec...</td>\n",
       "      <td>70937402</td>\n",
       "      <td>948</td>\n",
       "      <td>azure-devops</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;This should be caused by TLS1.2.&lt;/p&gt;\\n&lt;bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169258</th>\n",
       "      <td>70835504</td>\n",
       "      <td>display original list after shuffle function</td>\n",
       "      <td>&lt;p&gt;See my code snipped\\nI've an html list and ...</td>\n",
       "      <td>70835746</td>\n",
       "      <td>37</td>\n",
       "      <td>javascript</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;A short trick would be to store the &lt;code&gt;i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291164</th>\n",
       "      <td>72270744</td>\n",
       "      <td>Get sum of column values for specific rows onl...</td>\n",
       "      <td>&lt;p&gt;I am super new to power bi and Dax and i ne...</td>\n",
       "      <td>72279794</td>\n",
       "      <td>2107</td>\n",
       "      <td>powerbi|dax|calculated-columns</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;This is simple to do in DAX. Add the column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331925</th>\n",
       "      <td>71434362</td>\n",
       "      <td>How to check which row in producing LangDetect...</td>\n",
       "      <td>&lt;p&gt;I have a dataset of tweets that contains tw...</td>\n",
       "      <td>71434382</td>\n",
       "      <td>131</td>\n",
       "      <td>python-3.x|pandas|dataframe|twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;Use custom function for return &lt;code&gt;True&lt;/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "75793   73545119  Unzip .zip File without Writing to Disc from R...   \n",
       "151748  70934250  All self-hosted agents cannot connect to devop...   \n",
       "169258  70835504       display original list after shuffle function   \n",
       "291164  72270744  Get sum of column values for specific rows onl...   \n",
       "331925  71434362  How to check which row in producing LangDetect...   \n",
       "\n",
       "                                                     body  accepted_answer_id  \\\n",
       "75793   <p>Let me preface by stating that I' somewhat ...            73545325   \n",
       "151748  <p>All of our self-hosted agents cannot connec...            70937402   \n",
       "169258  <p>See my code snipped\\nI've an html list and ...            70835746   \n",
       "291164  <p>I am super new to power bi and Dax and i ne...            72279794   \n",
       "331925  <p>I have a dataset of tweets that contains tw...            71434382   \n",
       "\n",
       "        view_count                                 tags  answer_count  \\\n",
       "75793           60                       c#|asp.net|api             2   \n",
       "151748         948                         azure-devops             1   \n",
       "169258          37                           javascript             2   \n",
       "291164        2107       powerbi|dax|calculated-columns             2   \n",
       "331925         131  python-3.x|pandas|dataframe|twitter             1   \n",
       "\n",
       "        question_score  answer_score  \\\n",
       "75793                1             3   \n",
       "151748               0             3   \n",
       "169258               1             1   \n",
       "291164               0             1   \n",
       "331925               1             1   \n",
       "\n",
       "                                     stackoverflow_answer  \n",
       "75793   <p>Assuming you actually have a <code>.zip</co...  \n",
       "151748  <p>This should be caused by TLS1.2.</p>\\n<bloc...  \n",
       "169258  <p>A short trick would be to store the <code>i...  \n",
       "291164  <p>This is simple to do in DAX. Add the column...  \n",
       "331925  <p>Use custom function for return <code>True</...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly sample dataset\n",
    "fd_tiny = results.sample(frac=0.0001)\n",
    "fd_nano = results.sample(n=10)\n",
    "fd_1k   = results.sample(n=1000)\n",
    "fd_10k  = results.sample(n=10000)\n",
    "fd_100k = results.sample(n=100000)\n",
    "\n",
    "# Convenience: alias the filtered data so we can change it easily for later code\n",
    "wd = fd_nano\n",
    "\n",
    "# Dump info about the filtered result\n",
    "print(\"Number of questions in currently selected filtered dataset:\", len(wd))\n",
    "wd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip HTML from filtered dataset\n",
    "\n",
    "We decided we would strip HTML and use this \"stripped\" version as our default for evaluations. The stripped text is appended as a separate column in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# Separate out the text columns we want for convenience\n",
    "titles  = wd[\"title\"]\n",
    "bodies  = wd[\"body\"]\n",
    "answers = wd[\"stackoverflow_answer\"]\n",
    "\n",
    "# Sanity check (surely this will always be true, but *just in case*)\n",
    "if len(titles) == len(bodies) and len(titles) == len(answers):\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(\"columns are different lengths!\")\n",
    "\n",
    "# Create new lists to store HTML-stripped versions of text\n",
    "s_titles  = []\n",
    "s_bodies  = []\n",
    "s_answers = []\n",
    "\n",
    "# Iterating is slow(!) but comparatively easy to understand (modified Harvey approach)\n",
    "for idx, *row in wd.itertuples():\n",
    "    \n",
    "    # Strip HTML from title, question, and answer; save to lists\n",
    "    s_titles.append(soup(titles[idx], \"html.parser\").get_text())\n",
    "    s_bodies.append(soup(bodies[idx], \"html.parser\").get_text())\n",
    "    s_answers.append(soup(answers[idx], \"html.parser\").get_text())\n",
    "\n",
    "# Add the populated lists into our dataframe\n",
    "wd[\"stripped_title\"] = s_titles\n",
    "wd[\"stripped_body\"] = s_bodies\n",
    "wd[\"stripped_stackoverflow_answer\"] = s_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install OpenAI library and Configure OpenAI API Key\n",
    "\n",
    "Currently configured using secrets.json located at the root directory. An alternative method (which would require code changes) would be to read the system's environment variable.\n",
    "\n",
    "Key can be generated from: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mark\\anaconda3\\envs\\testenv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install OpenAI\n",
    "%pip install openai\n",
    "import openai\n",
    "\n",
    "# Function to load OpenAI API key from file\n",
    "# https://stackoverflow.com/a/76148268\n",
    "def load_api_key(secrets_file=\"secrets.json\"):\n",
    "    with open(secrets_file) as f:\n",
    "        secrets = json.load(f)\n",
    "    return secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Read and set our OpenAI API key\n",
    "api_key = load_api_key()\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataframe into chunks for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "      <th>stripped_title</th>\n",
       "      <th>stripped_body</th>\n",
       "      <th>stripped_stackoverflow_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75793</th>\n",
       "      <td>73545119</td>\n",
       "      <td>Unzip .zip File without Writing to Disc from R...</td>\n",
       "      <td>&lt;p&gt;Let me preface by stating that I' somewhat ...</td>\n",
       "      <td>73545325</td>\n",
       "      <td>60</td>\n",
       "      <td>c#|asp.net|api</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Assuming you actually have a &lt;code&gt;.zip&lt;/co...</td>\n",
       "      <td>Unzip .zip File without Writing to Disc from R...</td>\n",
       "      <td>Let me preface by stating that I' somewhat new...</td>\n",
       "      <td>Assuming you actually have a .zip file, you do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "75793  73545119  Unzip .zip File without Writing to Disc from R...   \n",
       "\n",
       "                                                    body  accepted_answer_id  \\\n",
       "75793  <p>Let me preface by stating that I' somewhat ...            73545325   \n",
       "\n",
       "       view_count            tags  answer_count  question_score  answer_score  \\\n",
       "75793          60  c#|asp.net|api             2               1             3   \n",
       "\n",
       "                                    stackoverflow_answer  \\\n",
       "75793  <p>Assuming you actually have a <code>.zip</co...   \n",
       "\n",
       "                                          stripped_title  \\\n",
       "75793  Unzip .zip File without Writing to Disc from R...   \n",
       "\n",
       "                                           stripped_body  \\\n",
       "75793  Let me preface by stating that I' somewhat new...   \n",
       "\n",
       "                           stripped_stackoverflow_answer  \n",
       "75793  Assuming you actually have a .zip file, you do...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into n parts (in our case 10) in a list\n",
    "wd_list = np.array_split(wd, 10)\n",
    "\n",
    "# Check the result of the first chunk\n",
    "wd_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get GPT answers to SO questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for rate limit handling with OpenAI API\n",
    "%pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to estimate token counts\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "MODEL_NAME = \"gpt-4\"\n",
    "ENCODING = tiktoken.encoding_for_model(MODEL_NAME)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    response = openai.ChatCompletion.create(**kwargs)\n",
    "    return response\n",
    "\n",
    "def chat_format(question):\n",
    "    \"\"\"Insert the full prompt into chat format.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "for chunk in wd_list:\n",
    "    GPT_answers = []\n",
    "    GPT_finished = []\n",
    "    full_responses = []\n",
    "\n",
    "    for idx, row in chunk.iterrows():\n",
    "\n",
    "        title_and_question = row[\"stripped_title\"] + \"\\n\\n\" + row[\"stripped_body\"]\n",
    "        SO_text = title_and_question + row[\"stripped_stackoverflow_answer\"]\n",
    "\n",
    "        # Estimate tokens for SO T+Q+A, and skip anything too long\n",
    "        if len(ENCODING.encode(SO_text)) < 4000:\n",
    "\n",
    "            # Get the response from GPT\n",
    "            prompt = chat_format(title_and_question)\n",
    "            GPT_answer = completion_with_backoff(model=MODEL_NAME, messages=prompt, temperature=0, max_tokens=2000)\n",
    "            extracted_answer = GPT_answer.choices[0].message.content\n",
    "\n",
    "            # Check if the GPT response completed or terminated early (because e.g. hit token limit)\n",
    "            if GPT_answer.choices[0].finish_reason == \"stop\":\n",
    "                finished = True\n",
    "            else:\n",
    "                finished = False\n",
    "\n",
    "        else:\n",
    "            extracted_answer = None\n",
    "            GPT_answer = None\n",
    "            finished = False\n",
    "\n",
    "        # Add to our lists\n",
    "        GPT_answers.append(extracted_answer)\n",
    "        GPT_finished.append(finished)\n",
    "        full_responses.append(GPT_answer)\n",
    "\n",
    "    # Add answers back into the chunk dataframe\n",
    "    COL_NAME = f\"{MODEL_NAME}_answer\"\n",
    "    chunk[COL_NAME] = GPT_answers\n",
    "    chunk[\"GPT_finished\"] = GPT_finished\n",
    "    chunk[\"full_GPT_response\"] = full_responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "      <th>stripped_title</th>\n",
       "      <th>stripped_body</th>\n",
       "      <th>stripped_stackoverflow_answer</th>\n",
       "      <th>gpt-3.5-turbo-16k_answer</th>\n",
       "      <th>full_GPT_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301250</th>\n",
       "      <td>71540756</td>\n",
       "      <td>419 Page Expired In Laravel Even after adding ...</td>\n",
       "      <td>&lt;p&gt;I am working on a Laravel 8 Framework,\\nI h...</td>\n",
       "      <td>71542495</td>\n",
       "      <td>2560</td>\n",
       "      <td>php|laravel|post|laravel-8|csrf</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;h3&gt;Laravel &amp;quot;419 Page Expired&amp;quot; Error...</td>\n",
       "      <td>419 Page Expired In Laravel Even after adding ...</td>\n",
       "      <td>I am working on a Laravel 8 Framework,\\nI have...</td>\n",
       "      <td>Laravel \"419 Page Expired\" Error Troubleshooti...</td>\n",
       "      <td>If you have already checked that the CSRF toke...</td>\n",
       "      <td>{'id': 'chatcmpl-80Stg7rYBYPh9T65RGSwBtQNbTHYv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "301250  71540756  419 Page Expired In Laravel Even after adding ...   \n",
       "\n",
       "                                                     body  accepted_answer_id  \\\n",
       "301250  <p>I am working on a Laravel 8 Framework,\\nI h...            71542495   \n",
       "\n",
       "        view_count                             tags  answer_count  \\\n",
       "301250        2560  php|laravel|post|laravel-8|csrf             2   \n",
       "\n",
       "        question_score  answer_score  \\\n",
       "301250               2             2   \n",
       "\n",
       "                                     stackoverflow_answer  \\\n",
       "301250  <h3>Laravel &quot;419 Page Expired&quot; Error...   \n",
       "\n",
       "                                           stripped_title  \\\n",
       "301250  419 Page Expired In Laravel Even after adding ...   \n",
       "\n",
       "                                            stripped_body  \\\n",
       "301250  I am working on a Laravel 8 Framework,\\nI have...   \n",
       "\n",
       "                            stripped_stackoverflow_answer  \\\n",
       "301250  Laravel \"419 Page Expired\" Error Troubleshooti...   \n",
       "\n",
       "                                 gpt-3.5-turbo-16k_answer  \\\n",
       "301250  If you have already checked that the CSRF toke...   \n",
       "\n",
       "                                        full_GPT_response  \n",
       "301250  {'id': 'chatcmpl-80Stg7rYBYPh9T65RGSwBtQNbTHYv...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result of first chunk\n",
    "wd_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "      <th>stripped_title</th>\n",
       "      <th>stripped_body</th>\n",
       "      <th>stripped_stackoverflow_answer</th>\n",
       "      <th>gpt-3.5-turbo-16k_answer</th>\n",
       "      <th>full_GPT_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153788</th>\n",
       "      <td>70546619</td>\n",
       "      <td>Why Typescript return type void in interface d...</td>\n",
       "      <td>&lt;p&gt;I'm trying two different classes in Typescr...</td>\n",
       "      <td>70546721</td>\n",
       "      <td>886</td>\n",
       "      <td>javascript|typescript</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;p&gt;The inferred type of the method without the...</td>\n",
       "      <td>Why Typescript return type void in interface d...</td>\n",
       "      <td>I'm trying two different classes in Typescript...</td>\n",
       "      <td>The inferred type of the method without the ex...</td>\n",
       "      <td>In TypeScript, when a class implements an inte...</td>\n",
       "      <td>{'id': 'chatcmpl-80Sven16rn48fpj47iEBNv7b10lOl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "153788  70546619  Why Typescript return type void in interface d...   \n",
       "\n",
       "                                                     body  accepted_answer_id  \\\n",
       "153788  <p>I'm trying two different classes in Typescr...            70546721   \n",
       "\n",
       "        view_count                   tags  answer_count  question_score  \\\n",
       "153788         886  javascript|typescript             1               5   \n",
       "\n",
       "        answer_score                               stackoverflow_answer  \\\n",
       "153788             7  <p>The inferred type of the method without the...   \n",
       "\n",
       "                                           stripped_title  \\\n",
       "153788  Why Typescript return type void in interface d...   \n",
       "\n",
       "                                            stripped_body  \\\n",
       "153788  I'm trying two different classes in Typescript...   \n",
       "\n",
       "                            stripped_stackoverflow_answer  \\\n",
       "153788  The inferred type of the method without the ex...   \n",
       "\n",
       "                                 gpt-3.5-turbo-16k_answer  \\\n",
       "153788  In TypeScript, when a class implements an inte...   \n",
       "\n",
       "                                        full_GPT_response  \n",
       "153788  {'id': 'chatcmpl-80Sven16rn48fpj47iEBNv7b10lOl...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result of last chun\n",
    "wd_list[9].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary fix to column name TODO: REMOVE\n",
    "\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-16k\"\n",
    "# col_name = f\"{MODEL_NAME}_answer\"\n",
    "\n",
    "# wd.drop(columns=[\"GPT_3.5_answer\", \"gpt-3.5-turbo-16k_answer\"], inplace=True)\n",
    "\n",
    "# wd.rename(columns={\"gpt-3.5-turbo-16k\": \"gpt-3.5-turbo-16k_answer\"}, inplace=True)\n",
    "\n",
    "# wd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare JSONL file for evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip and save a copy of the GPT answer\n",
    "#   (so that the eval is on fair footing, with HTML tags removed from both human and AI)\n",
    "\n",
    "for index, chunk in enumerate(wd_list):\n",
    "\n",
    "    # Separate out the text columns we want for convenience\n",
    "    titles  = chunk[\"title\"]\n",
    "    bodies  = chunk[\"body\"]\n",
    "    answers = chunk[\"stackoverflow_answer\"]\n",
    "\n",
    "    # Create a new list to store HTML-stripped versions of text\n",
    "    s_gpt_answers  = []\n",
    "\n",
    "    # Iterating is slow(!) but comparatively easy to understand (modified Harvey approach)\n",
    "    for idx, *row in chunk.itertuples():\n",
    "        \n",
    "        # Strip HTML from GPT's answer; save to list\n",
    "        s_gpt_answers.append(soup(chunk[COL_NAME][idx], \"html.parser\").get_text())\n",
    "\n",
    "    # Add the populated lists into our dataframe\n",
    "    stripped_col_name = \"stripped_\" + COL_NAME\n",
    "    chunk[stripped_col_name] = s_gpt_answers\n",
    "\n",
    "    # Preview result\n",
    "    #chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "      <th>stripped_title</th>\n",
       "      <th>stripped_body</th>\n",
       "      <th>stripped_stackoverflow_answer</th>\n",
       "      <th>gpt-3.5-turbo-16k_answer</th>\n",
       "      <th>full_GPT_response</th>\n",
       "      <th>stripped_gpt-3.5-turbo-16k_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301250</th>\n",
       "      <td>71540756</td>\n",
       "      <td>419 Page Expired In Laravel Even after adding ...</td>\n",
       "      <td>&lt;p&gt;I am working on a Laravel 8 Framework,\\nI h...</td>\n",
       "      <td>71542495</td>\n",
       "      <td>2560</td>\n",
       "      <td>php|laravel|post|laravel-8|csrf</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;h3&gt;Laravel &amp;quot;419 Page Expired&amp;quot; Error...</td>\n",
       "      <td>419 Page Expired In Laravel Even after adding ...</td>\n",
       "      <td>I am working on a Laravel 8 Framework,\\nI have...</td>\n",
       "      <td>Laravel \"419 Page Expired\" Error Troubleshooti...</td>\n",
       "      <td>If you have already checked that the CSRF toke...</td>\n",
       "      <td>{'id': 'chatcmpl-80Stg7rYBYPh9T65RGSwBtQNbTHYv...</td>\n",
       "      <td>If you have already checked that the CSRF toke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "301250  71540756  419 Page Expired In Laravel Even after adding ...   \n",
       "\n",
       "                                                     body  accepted_answer_id  \\\n",
       "301250  <p>I am working on a Laravel 8 Framework,\\nI h...            71542495   \n",
       "\n",
       "        view_count                             tags  answer_count  \\\n",
       "301250        2560  php|laravel|post|laravel-8|csrf             2   \n",
       "\n",
       "        question_score  answer_score  \\\n",
       "301250               2             2   \n",
       "\n",
       "                                     stackoverflow_answer  \\\n",
       "301250  <h3>Laravel &quot;419 Page Expired&quot; Error...   \n",
       "\n",
       "                                           stripped_title  \\\n",
       "301250  419 Page Expired In Laravel Even after adding ...   \n",
       "\n",
       "                                            stripped_body  \\\n",
       "301250  I am working on a Laravel 8 Framework,\\nI have...   \n",
       "\n",
       "                            stripped_stackoverflow_answer  \\\n",
       "301250  Laravel \"419 Page Expired\" Error Troubleshooti...   \n",
       "\n",
       "                                 gpt-3.5-turbo-16k_answer  \\\n",
       "301250  If you have already checked that the CSRF toke...   \n",
       "\n",
       "                                        full_GPT_response  \\\n",
       "301250  {'id': 'chatcmpl-80Stg7rYBYPh9T65RGSwBtQNbTHYv...   \n",
       "\n",
       "                        stripped_gpt-3.5-turbo-16k_answer  \n",
       "301250  If you have already checked that the CSRF toke...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first chunk\n",
    "wd_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "      <th>stripped_title</th>\n",
       "      <th>stripped_body</th>\n",
       "      <th>stripped_stackoverflow_answer</th>\n",
       "      <th>gpt-3.5-turbo-16k_answer</th>\n",
       "      <th>full_GPT_response</th>\n",
       "      <th>stripped_gpt-3.5-turbo-16k_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153788</th>\n",
       "      <td>70546619</td>\n",
       "      <td>Why Typescript return type void in interface d...</td>\n",
       "      <td>&lt;p&gt;I'm trying two different classes in Typescr...</td>\n",
       "      <td>70546721</td>\n",
       "      <td>886</td>\n",
       "      <td>javascript|typescript</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;p&gt;The inferred type of the method without the...</td>\n",
       "      <td>Why Typescript return type void in interface d...</td>\n",
       "      <td>I'm trying two different classes in Typescript...</td>\n",
       "      <td>The inferred type of the method without the ex...</td>\n",
       "      <td>In TypeScript, when a class implements an inte...</td>\n",
       "      <td>{'id': 'chatcmpl-80Sven16rn48fpj47iEBNv7b10lOl...</td>\n",
       "      <td>In TypeScript, when a class implements an inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "153788  70546619  Why Typescript return type void in interface d...   \n",
       "\n",
       "                                                     body  accepted_answer_id  \\\n",
       "153788  <p>I'm trying two different classes in Typescr...            70546721   \n",
       "\n",
       "        view_count                   tags  answer_count  question_score  \\\n",
       "153788         886  javascript|typescript             1               5   \n",
       "\n",
       "        answer_score                               stackoverflow_answer  \\\n",
       "153788             7  <p>The inferred type of the method without the...   \n",
       "\n",
       "                                           stripped_title  \\\n",
       "153788  Why Typescript return type void in interface d...   \n",
       "\n",
       "                                            stripped_body  \\\n",
       "153788  I'm trying two different classes in Typescript...   \n",
       "\n",
       "                            stripped_stackoverflow_answer  \\\n",
       "153788  The inferred type of the method without the ex...   \n",
       "\n",
       "                                 gpt-3.5-turbo-16k_answer  \\\n",
       "153788  In TypeScript, when a class implements an inte...   \n",
       "\n",
       "                                        full_GPT_response  \\\n",
       "153788  {'id': 'chatcmpl-80Sven16rn48fpj47iEBNv7b10lOl...   \n",
       "\n",
       "                        stripped_gpt-3.5-turbo-16k_answer  \n",
       "153788  In TypeScript, when a class implements an inte...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check last chunk\n",
    "wd_list[9].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_0.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_1.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_2.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_3.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_4.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_5.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_6.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_7.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_8.jsonl\n",
      "Saved JSONL file: c:\\Users\\Mark\\Documents\\A2I2 T2 2023\\temp\\samples\\new_samples_9.jsonl\n"
     ]
    }
   ],
   "source": [
    "for index, chunk in enumerate(wd_list):\n",
    "\n",
    "    json_list = []\n",
    "    for idx, row in chunk.iterrows():\n",
    "        \n",
    "        # Strip and chat-format the text as appropriate\n",
    "        title_and_question = row[\"stripped_title\"] + \"\\n\\n\" + row[\"stripped_body\"]\n",
    "        prompt = chat_format(title_and_question)\n",
    "\n",
    "        # Create the JSON object using the stripped and chat-formatted text\n",
    "        json_object = {\n",
    "            \"input\": prompt,\n",
    "            \"ideal\": row[\"stripped_stackoverflow_answer\"],\n",
    "            \"completion\": row[\"stripped_gpt-3.5-turbo-16k_answer\"]\n",
    "        }\n",
    "\n",
    "        # TODO: update to skip this json object if there's no GPT answer\n",
    "\n",
    "        # Add the object to our list\n",
    "        json_list.append(json.dumps(json_object))\n",
    "\n",
    "    # because re-running the notebook changes the sampling we DON'T want a persistent jsonl file\n",
    "    #   this step relies on the directories existing; they are not created here\n",
    "    #   so this will fail with e.g. FileNotFoundError if they don't exist\n",
    "    JSONL_FILENAME = f\"new_samples_{index}.jsonl\"\n",
    "    JSONL_FILEPATH = os.path.join(cwd, \"temp\", \"samples\", JSONL_FILENAME)\n",
    "    with open(JSONL_FILEPATH, \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(json_list))\n",
    "        print(\"Saved JSONL file: \" + JSONL_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: remove/update old stuff below (from pre-evals-solved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install OpenAI evals\n",
    "\n",
    "The T1 intern used their own modified evals (speculated to be for efficiency reasons?). For T2 we're trying the unmodified evals. They used the `-e` flag in their installation because they were modifying evals - since we're not doing that it's not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'evals'...\n",
      "Updating files:  38% (443/1136)\n",
      "Updating files:  39% (444/1136)\n",
      "Updating files:  40% (455/1136)\n",
      "Updating files:  41% (466/1136)\n",
      "Updating files:  42% (478/1136)\n",
      "Updating files:  43% (489/1136)\n",
      "Updating files:  44% (500/1136)\n",
      "Updating files:  45% (512/1136)\n",
      "Updating files:  46% (523/1136)\n",
      "Updating files:  47% (534/1136)\n",
      "Updating files:  48% (546/1136)\n",
      "Updating files:  49% (557/1136)\n",
      "Updating files:  50% (568/1136)\n",
      "Updating files:  51% (580/1136)\n",
      "Updating files:  52% (591/1136)\n",
      "Updating files:  53% (603/1136)\n",
      "Updating files:  54% (614/1136)\n",
      "Updating files:  55% (625/1136)\n",
      "Updating files:  56% (637/1136)\n",
      "Updating files:  57% (648/1136)\n",
      "Updating files:  58% (659/1136)\n",
      "Updating files:  59% (671/1136)\n",
      "Updating files:  60% (682/1136)\n",
      "Updating files:  61% (693/1136)\n",
      "Updating files:  62% (705/1136)\n",
      "Updating files:  63% (716/1136)\n",
      "Updating files:  64% (728/1136)\n",
      "Updating files:  65% (739/1136)\n",
      "Updating files:  66% (750/1136)\n",
      "Updating files:  67% (762/1136)\n",
      "Updating files:  68% (773/1136)\n",
      "Updating files:  69% (784/1136)\n",
      "Updating files:  70% (796/1136)\n",
      "Updating files:  71% (807/1136)\n",
      "Updating files:  72% (818/1136)\n",
      "Updating files:  73% (830/1136)\n",
      "Updating files:  74% (841/1136)\n",
      "Updating files:  75% (852/1136)\n",
      "Updating files:  76% (864/1136)\n",
      "Updating files:  77% (875/1136)\n",
      "Updating files:  78% (887/1136)\n",
      "Updating files:  79% (898/1136)\n",
      "Updating files:  80% (909/1136)\n",
      "Updating files:  81% (921/1136)\n",
      "Updating files:  82% (932/1136)\n",
      "Updating files:  83% (943/1136)\n",
      "Updating files:  84% (955/1136)\n",
      "Updating files:  85% (966/1136)\n",
      "Updating files:  86% (977/1136)\n",
      "Updating files:  87% (989/1136)\n",
      "Updating files:  88% (1000/1136)\n",
      "Updating files:  89% (1012/1136)\n",
      "Updating files:  90% (1023/1136)\n",
      "Updating files:  91% (1034/1136)\n",
      "Updating files:  92% (1046/1136)\n",
      "Updating files:  93% (1057/1136)\n",
      "Updating files:  94% (1068/1136)\n",
      "Updating files:  95% (1080/1136)\n",
      "Updating files:  96% (1091/1136)\n",
      "Updating files:  97% (1102/1136)\n",
      "Updating files:  98% (1114/1136)\n",
      "Updating files:  99% (1125/1136)\n",
      "Updating files: 100% (1136/1136)\n",
      "Updating files: 100% (1136/1136), done.\n",
      "Filtering content:   2% (14/557), 21.49 MiB | 23.67 MiB/s\n",
      "Filtering content:   3% (17/557), 21.49 MiB | 23.67 MiB/s\n",
      "Filtering content:   4% (23/557), 23.67 MiB | 13.54 MiB/s\n",
      "Filtering content:   5% (28/557), 23.67 MiB | 13.54 MiB/s\n",
      "Filtering content:   6% (34/557), 23.67 MiB | 13.54 MiB/s\n",
      "Filtering content:   7% (39/557), 23.67 MiB | 13.54 MiB/s\n",
      "Filtering content:   7% (40/557), 23.67 MiB | 13.54 MiB/s\n",
      "Filtering content:   8% (45/557), 25.67 MiB | 10.64 MiB/s\n",
      "Filtering content:   9% (51/557), 25.67 MiB | 10.64 MiB/s\n",
      "Filtering content:  10% (56/557), 26.26 MiB | 8.27 MiB/s \n",
      "Filtering content:  11% (62/557), 26.26 MiB | 8.27 MiB/s\n",
      "Filtering content:  12% (67/557), 26.26 MiB | 8.27 MiB/s\n",
      "Filtering content:  12% (68/557), 26.26 MiB | 8.27 MiB/s\n",
      "Filtering content:  13% (73/557), 26.58 MiB | 6.78 MiB/s\n",
      "Filtering content:  14% (78/557), 26.58 MiB | 6.78 MiB/s\n",
      "Filtering content:  15% (84/557), 26.58 MiB | 6.78 MiB/s\n",
      "Filtering content:  16% (90/557), 26.72 MiB | 5.68 MiB/s\n",
      "Filtering content:  17% (95/557), 26.72 MiB | 5.68 MiB/s\n",
      "Filtering content:  17% (96/557), 26.72 MiB | 5.68 MiB/s\n",
      "Filtering content:  18% (101/557), 26.72 MiB | 5.68 MiB/s\n",
      "Filtering content:  19% (106/557), 36.07 MiB | 5.05 MiB/s\n",
      "Filtering content:  20% (112/557), 47.78 MiB | 6.44 MiB/s\n",
      "Filtering content:  20% (115/557), 47.78 MiB | 6.44 MiB/s\n",
      "Filtering content:  21% (117/557), 51.49 MiB | 4.89 MiB/s\n",
      "Filtering content:  22% (123/557), 53.25 MiB | 4.86 MiB/s\n",
      "Filtering content:  22% (124/557), 53.25 MiB | 4.86 MiB/s\n",
      "Filtering content:  23% (129/557), 54.34 MiB | 4.69 MiB/s\n",
      "Filtering content:  24% (134/557), 55.30 MiB | 4.77 MiB/s\n",
      "Filtering content:  25% (140/557), 55.86 MiB | 4.79 MiB/s\n",
      "Filtering content:  26% (145/557), 56.30 MiB | 4.71 MiB/s\n",
      "Filtering content:  27% (151/557), 56.56 MiB | 5.61 MiB/s\n",
      "Filtering content:  28% (156/557), 56.56 MiB | 5.61 MiB/s\n",
      "Filtering content:  28% (156/557), 137.39 MiB | 19.48 MiB/s\n",
      "Filtering content:  29% (162/557), 137.39 MiB | 19.48 MiB/s\n",
      "Filtering content:  30% (168/557), 137.39 MiB | 19.48 MiB/s\n",
      "Filtering content:  31% (173/557), 137.71 MiB | 17.60 MiB/s\n",
      "Filtering content:  31% (178/557), 137.71 MiB | 17.60 MiB/s\n",
      "Filtering content:  32% (179/557), 137.71 MiB | 17.60 MiB/s\n",
      "Filtering content:  33% (184/557), 137.86 MiB | 16.74 MiB/s\n",
      "Filtering content:  34% (190/557), 137.86 MiB | 16.74 MiB/s\n",
      "Filtering content:  35% (195/557), 137.92 MiB | 15.95 MiB/s\n",
      "Filtering content:  35% (198/557), 137.92 MiB | 15.95 MiB/s\n",
      "Filtering content:  35% (200/557), 300.68 MiB | 40.78 MiB/s\n",
      "Filtering content:  36% (201/557), 300.68 MiB | 40.78 MiB/s\n",
      "Filtering content:  37% (207/557), 303.15 MiB | 35.61 MiB/s\n",
      "Filtering content:  37% (209/557), 303.15 MiB | 35.61 MiB/s\n",
      "Filtering content:  38% (212/557), 303.15 MiB | 35.61 MiB/s\n",
      "Filtering content:  39% (218/557), 352.47 MiB | 42.74 MiB/s\n",
      "Filtering content:  40% (223/557), 357.80 MiB | 44.72 MiB/s\n",
      "Filtering content:  41% (229/557), 357.80 MiB | 44.72 MiB/s\n",
      "Filtering content:  42% (234/557), 359.48 MiB | 44.71 MiB/s\n",
      "Filtering content:  43% (240/557), 359.48 MiB | 44.71 MiB/s\n",
      "Filtering content:  44% (246/557), 359.48 MiB | 44.71 MiB/s\n",
      "Filtering content:  45% (251/557), 360.46 MiB | 33.62 MiB/s\n",
      "Filtering content:  45% (252/557), 360.46 MiB | 33.62 MiB/s\n",
      "Filtering content:  46% (257/557), 360.46 MiB | 33.62 MiB/s\n",
      "Filtering content:  47% (262/557), 360.86 MiB | 33.58 MiB/s\n",
      "Filtering content:  48% (268/557), 360.86 MiB | 33.58 MiB/s\n",
      "Filtering content:  49% (273/557), 360.86 MiB | 33.58 MiB/s\n",
      "Filtering content:  49% (278/557), 361.16 MiB | 33.79 MiB/s\n",
      "Filtering content:  50% (279/557), 361.16 MiB | 33.79 MiB/s\n",
      "Filtering content:  51% (285/557), 361.16 MiB | 33.79 MiB/s\n",
      "Filtering content:  52% (290/557), 361.30 MiB | 34.56 MiB/s\n",
      "Filtering content:  53% (296/557), 361.30 MiB | 34.56 MiB/s\n",
      "Filtering content:  54% (301/557), 361.30 MiB | 34.56 MiB/s\n",
      "Filtering content:  55% (307/557), 365.58 MiB | 6.89 MiB/s \n",
      "Filtering content:  55% (309/557), 365.58 MiB | 6.89 MiB/s\n",
      "Filtering content:  56% (312/557), 405.90 MiB | 11.97 MiB/s\n",
      "Filtering content:  56% (317/557), 419.63 MiB | 7.83 MiB/s \n",
      "Filtering content:  57% (318/557), 419.63 MiB | 7.83 MiB/s\n",
      "Filtering content:  58% (324/557), 433.56 MiB | 8.79 MiB/s\n",
      "Filtering content:  59% (329/557), 455.06 MiB | 10.99 MiB/s\n",
      "Filtering content:  59% (334/557), 455.06 MiB | 10.99 MiB/s\n",
      "Filtering content:  60% (335/557), 455.06 MiB | 10.99 MiB/s\n",
      "Filtering content:  61% (340/557), 455.06 MiB | 10.99 MiB/s\n",
      "Filtering content:  62% (346/557), 466.66 MiB | 12.09 MiB/s\n",
      "Filtering content:  63% (351/557), 466.66 MiB | 12.09 MiB/s\n",
      "Filtering content:  63% (356/557), 468.08 MiB | 12.08 MiB/s\n",
      "Filtering content:  64% (357/557), 468.08 MiB | 12.08 MiB/s\n",
      "Filtering content:  65% (363/557), 468.08 MiB | 12.08 MiB/s\n",
      "Filtering content:  66% (368/557), 468.08 MiB | 12.08 MiB/s\n",
      "Filtering content:  67% (374/557), 468.08 MiB | 12.08 MiB/s\n",
      "Filtering content:  68% (379/557), 468.78 MiB | 12.14 MiB/s\n",
      "Filtering content:  69% (385/557), 468.78 MiB | 12.14 MiB/s\n",
      "Filtering content:  69% (389/557), 468.78 MiB | 12.14 MiB/s\n",
      "Filtering content:  70% (390/557), 468.78 MiB | 12.14 MiB/s\n",
      "Filtering content:  71% (396/557), 468.93 MiB | 12.20 MiB/s\n",
      "Filtering content:  71% (401/557), 468.93 MiB | 12.20 MiB/s\n",
      "Filtering content:  72% (402/557), 481.10 MiB | 15.08 MiB/s\n",
      "Filtering content:  73% (407/557), 481.10 MiB | 15.08 MiB/s\n",
      "Filtering content:  74% (413/557), 481.10 MiB | 15.08 MiB/s\n",
      "Filtering content:  75% (418/557), 544.38 MiB | 18.24 MiB/s\n",
      "Filtering content:  76% (424/557), 544.38 MiB | 18.24 MiB/s\n",
      "Filtering content:  77% (429/557), 544.38 MiB | 18.24 MiB/s\n",
      "Filtering content:  78% (435/557), 546.28 MiB | 16.69 MiB/s\n",
      "Filtering content:  79% (441/557), 546.28 MiB | 16.69 MiB/s\n",
      "Filtering content:  80% (446/557), 546.97 MiB | 14.94 MiB/s\n",
      "Filtering content:  81% (452/557), 546.97 MiB | 14.94 MiB/s\n",
      "Filtering content:  82% (457/557), 546.97 MiB | 14.94 MiB/s\n",
      "Filtering content:  83% (463/557), 547.42 MiB | 12.27 MiB/s\n",
      "Filtering content:  84% (468/557), 547.42 MiB | 12.27 MiB/s\n",
      "Filtering content:  85% (474/557), 547.42 MiB | 12.27 MiB/s\n",
      "Filtering content:  86% (480/557), 547.56 MiB | 10.91 MiB/s\n",
      "Filtering content:  87% (485/557), 547.56 MiB | 10.91 MiB/s\n",
      "Filtering content:  88% (491/557), 547.64 MiB | 10.88 MiB/s\n",
      "Filtering content:  89% (496/557), 547.64 MiB | 10.88 MiB/s\n",
      "Filtering content:  89% (501/557), 547.64 MiB | 10.88 MiB/s\n",
      "Filtering content:  90% (502/557), 548.34 MiB | 9.68 MiB/s \n",
      "Filtering content:  90% (506/557), 548.34 MiB | 9.68 MiB/s\n",
      "Filtering content:  91% (507/557), 548.34 MiB | 9.68 MiB/s\n",
      "Filtering content:  92% (513/557), 558.51 MiB | 10.89 MiB/s\n",
      "Filtering content:  93% (519/557), 558.51 MiB | 10.89 MiB/s\n",
      "Filtering content:  94% (524/557), 575.90 MiB | 16.73 MiB/s\n",
      "Filtering content:  94% (525/557), 575.90 MiB | 16.73 MiB/s\n",
      "Filtering content:  95% (530/557), 575.90 MiB | 16.73 MiB/s\n",
      "Filtering content:  96% (535/557), 577.15 MiB | 5.76 MiB/s \n",
      "Filtering content:  97% (541/557), 577.15 MiB | 5.76 MiB/s\n",
      "Filtering content:  98% (546/557), 577.15 MiB | 5.76 MiB/s\n",
      "Filtering content:  99% (552/557), 577.48 MiB | 5.51 MiB/s\n",
      "Filtering content:  99% (554/557), 577.48 MiB | 5.51 MiB/s\n",
      "Filtering content: 100% (557/557), 577.48 MiB | 5.51 MiB/s\n",
      "Filtering content: 100% (557/557), 577.50 MiB | 15.04 MiB/s, done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch: Fetching all references...\n",
      "Collecting evals\n",
      "  Using cached evals-1.0.3.post1-py3-none-any.whl (7.8 MB)\n",
      "Collecting mypy (from evals)\n",
      "  Obtaining dependency information for mypy from https://files.pythonhosted.org/packages/4e/11/ac861ca5d9b16fd5b781c1941254d4e382e8eaab90e11f41f193d9222b7e/mypy-1.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached mypy-1.5.1-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: openai>=0.27.2 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (0.27.10)\n",
      "Collecting tiktoken (from evals)\n",
      "  Using cached tiktoken-0.4.0-cp311-cp311-win_amd64.whl (635 kB)\n",
      "Collecting blobfile (from evals)\n",
      "  Using cached blobfile-2.0.2-py3-none-any.whl (74 kB)\n",
      "Collecting backoff (from evals)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (1.25.2)\n",
      "Collecting snowflake-connector-python[pandas] (from evals)\n",
      "  Obtaining dependency information for snowflake-connector-python[pandas] from https://files.pythonhosted.org/packages/f1/78/adcecaf1ea13bfaf68662d218b25157c96d060709be63efc98158bad408b/snowflake_connector_python-3.1.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached snowflake_connector_python-3.1.1-cp311-cp311-win_amd64.whl.metadata (55 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (2.0.3)\n",
      "Collecting fire (from evals)\n",
      "  Using cached fire-0.5.0-py2.py3-none-any.whl\n",
      "Collecting pydantic (from evals)\n",
      "  Obtaining dependency information for pydantic from https://files.pythonhosted.org/packages/82/06/fafdc75e48b248eff364b4249af4bcc6952225e8f20e8205820afc66e88e/pydantic-2.3.0-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.3.0-py3-none-any.whl.metadata (148 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (4.66.1)\n",
      "Collecting nltk (from evals)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting filelock (from evals)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/52/90/45223db4e1df30ff14e8aebf9a1bf0222da2e7b49e53692c968f36817812/filelock-3.12.3-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.12.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting mock (from evals)\n",
      "  Obtaining dependency information for mock from https://files.pythonhosted.org/packages/6b/20/471f41173930550f279ccb65596a5ac19b9ac974a8d93679bcd3e0c31498/mock-5.1.0-py3-none-any.whl.metadata\n",
      "  Using cached mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langdetect (from evals)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: termcolor in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (2.3.0)\n",
      "Collecting lz4 (from evals)\n",
      "  Using cached lz4-4.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Requirement already satisfied: pyzstd in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (0.15.9)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (6.0.1)\n",
      "Collecting sacrebleu (from evals)\n",
      "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (3.7.2)\n",
      "Requirement already satisfied: setuptools-scm in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from evals) (7.1.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from openai>=0.27.2->evals) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from openai>=0.27.2->evals) (3.8.5)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from blobfile->evals) (3.18.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from blobfile->evals) (1.26.16)\n",
      "Requirement already satisfied: lxml~=4.9 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from blobfile->evals) (4.9.2)\n",
      "Requirement already satisfied: six in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from fire->evals) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from matplotlib->evals) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from mypy->evals) (4.7.1)\n",
      "Collecting mypy-extensions>=1.0.0 (from mypy->evals)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting click (from nltk->evals)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->evals)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from nltk->evals) (2023.8.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from pandas->evals) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from pandas->evals) (2023.3)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->evals)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from pydantic->evals) (2.6.3)\n",
      "Collecting portalocker (from sacrebleu->evals)\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from sacrebleu->evals) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from sacrebleu->evals) (0.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from setuptools-scm->evals) (68.0.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (1.15.1)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (41.0.2)\n",
      "Collecting oscrypto<2.0.0 (from snowflake-connector-python[pandas]->evals)\n",
      "  Using cached oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (23.2.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (2.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (2023.7.22)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (2.4.0)\n",
      "Collecting platformdirs<3.9.0,>=2.6.0 (from snowflake-connector-python[pandas]->evals)\n",
      "  Obtaining dependency information for platformdirs<3.9.0,>=2.6.0 from https://files.pythonhosted.org/packages/9e/d8/563a9fc17153c588c8c2042d2f0f84a89057cdb1c30270f589c88b42d62c/platformdirs-3.8.1-py3-none-any.whl.metadata\n",
      "  Using cached platformdirs-3.8.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (0.12.1)\n",
      "Requirement already satisfied: pyarrow<10.1.0,>=10.0.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from snowflake-connector-python[pandas]->evals) (10.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]->evals) (2.21)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from aiohttp->openai>=0.27.2->evals) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from aiohttp->openai>=0.27.2->evals) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from aiohttp->openai>=0.27.2->evals) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from aiohttp->openai>=0.27.2->evals) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from aiohttp->openai>=0.27.2->evals) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from aiohttp->openai>=0.27.2->evals) (1.3.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\mark\\anaconda3\\envs\\a2i2\\lib\\site-packages (from portalocker->sacrebleu->evals) (305.1)\n",
      "Using cached filelock-3.12.3-py3-none-any.whl (11 kB)\n",
      "Using cached mock-5.1.0-py3-none-any.whl (30 kB)\n",
      "Using cached mypy-1.5.1-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "Using cached pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
      "Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Using cached platformdirs-3.8.1-py3-none-any.whl (16 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached snowflake_connector_python-3.1.1-cp311-cp311-win_amd64.whl (10.7 MB)\n",
      "Installing collected packages: portalocker, platformdirs, oscrypto, mypy-extensions, mock, lz4, langdetect, joblib, fire, filelock, click, backoff, annotated-types, tiktoken, sacrebleu, pydantic, nltk, mypy, blobfile, snowflake-connector-python, evals\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 3.10.0\n",
      "    Uninstalling platformdirs-3.10.0:\n",
      "      Successfully uninstalled platformdirs-3.10.0\n",
      "Successfully installed annotated-types-0.5.0 backoff-2.2.1 blobfile-2.0.2 click-8.1.7 evals-1.0.3.post1 filelock-3.12.3 fire-0.5.0 joblib-1.3.2 langdetect-1.0.9 lz4-4.3.2 mock-5.1.0 mypy-1.5.1 mypy-extensions-1.0.0 nltk-3.8.1 oscrypto-1.3.0 platformdirs-3.8.1 portalocker-2.7.0 pydantic-2.3.0 sacrebleu-2.3.1 snowflake-connector-python-3.1.1 tiktoken-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# openai evals uses git-lfs, but installation may be system-specific\n",
    "#!git lfs install\n",
    "\n",
    "# get a local copy of evals (and if one already exists, nuke it first)\n",
    "try:\n",
    "    !rm -rf evals\n",
    "finally:\n",
    "    !git clone https://github.com/openai/evals.git\n",
    "\n",
    "# TODO: the -e thing needs to be added back, and markdown cell updated accordingly\n",
    "# complete the remaining lfs setup steps\n",
    "!cd evals\n",
    "!git lfs fetch --all\n",
    "!git lfs pull\n",
    "!cd evals\n",
    "%pip install evals -e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use/Run evals\n",
    "\n",
    "This also simultaneously queries OpenAI's models for answers (they're not generated beforehand and then fed into the evaluator).\n",
    "\n",
    "(As an aside, while using evals without both magic commands and manual file creation is possible (see https://medium.com/@sergioli/evaluating-chatgpt-using-openai-evals-7ca85c0ad139), it's comparatively more complex.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how the lists here are appended with an extra set of quotes\n",
    "#   this is being done because we're running shell commands that need quotes\n",
    "\n",
    "# Construct list of sample file paths\n",
    "sample_paths = []\n",
    "for index, chunk in enumerate(wd_list):\n",
    "    sample_path = os.path.join(cwd, \"eval_samples\", f\"new_samples_{index}.jsonl\")\n",
    "    sample_paths.append(f\"{sample_path}\")\n",
    "\n",
    "# Construct list of record file paths\n",
    "record_paths = []\n",
    "for index, chunk in enumerate(wd_list):\n",
    "    record_path = os.path.join(cwd, \"eval_records\", f\"eval_record_{index}.jsonl\")\n",
    "    record_paths.append(f'\\\"{record_path}\\\"')\n",
    "\n",
    "# Construct list of log file paths\n",
    "log_paths = []\n",
    "for index, chunk in enumerate(wd_list):\n",
    "    log_path = os.path.join(cwd, \"eval_logs\", f\"eval_log_{index}.jsonl\")\n",
    "    log_paths.append(f'\\\"{log_path}\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.95s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.95s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.88s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.88s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.05s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.05s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.35s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.35s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.80s/it]\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.80s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.41s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.34s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.34s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.14s/it]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.14s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.43s/it]\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.43s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.15s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.15s/it]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "samples_file_path = os.path.join(cwd, \"evals\", \"evals\", \"registry\", \"data\", \"coqa\", \"samples.jsonl\")\n",
    "\n",
    "# Run chunked evals\n",
    "for index, chunk in enumerate(wd_list):\n",
    "\n",
    "    # Update the samples file programmatically each iteration\n",
    "    shutil.copy(sample_paths[index], samples_file_path)\n",
    "\n",
    "    # Run the evaluation and save the results (records) and log file as specified\n",
    "    record = record_paths[index]\n",
    "    log = log_paths[index]\n",
    "    !oaieval gpt-4 coqa-fact --record_path $record --log_to_file $log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>question_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>stackoverflow_answer</th>\n",
       "      <th>stripped_title</th>\n",
       "      <th>stripped_body</th>\n",
       "      <th>stripped_stackoverflow_answer</th>\n",
       "      <th>gpt-3.5-turbo-16k_answer</th>\n",
       "      <th>stripped_gpt-3.5-turbo-16k_answer</th>\n",
       "      <th>eval_choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196461</td>\n",
       "      <td>71067715</td>\n",
       "      <td>CRA error. Html Webpack Plugin: Error: Child c...</td>\n",
       "      <td>&lt;p&gt;I create a default react app with &lt;code&gt;npx...</td>\n",
       "      <td>71086154</td>\n",
       "      <td>221</td>\n",
       "      <td>node.js|reactjs|webpack|create-react-app</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Solution: install &lt;strong&gt;react-scripts@4.0...</td>\n",
       "      <td>CRA error. Html Webpack Plugin: Error: Child c...</td>\n",
       "      <td>I create a default react app with npx create-r...</td>\n",
       "      <td>Solution: install react-scripts@4.0.3. If you ...</td>\n",
       "      <td>It seems like you are encountering an error re...</td>\n",
       "      <td>It seems like you are encountering an error re...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243249</td>\n",
       "      <td>71098325</td>\n",
       "      <td>Hyperledger Fabric | Orderer PODs keeps restar...</td>\n",
       "      <td>&lt;p&gt;I'm running Hyperledger Fabric network in A...</td>\n",
       "      <td>71168925</td>\n",
       "      <td>239</td>\n",
       "      <td>azure|kubernetes|hyperledger-fabric|raft</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Turns out my WAL logs directory was deleted...</td>\n",
       "      <td>Hyperledger Fabric | Orderer PODs keeps restar...</td>\n",
       "      <td>I'm running Hyperledger Fabric network in Azur...</td>\n",
       "      <td>Turns out my WAL logs directory was deleted. A...</td>\n",
       "      <td>The error message suggests that the raft log o...</td>\n",
       "      <td>The error message suggests that the raft log o...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375295</td>\n",
       "      <td>73155785</td>\n",
       "      <td>Grouping character strings</td>\n",
       "      <td>&lt;p&gt;I have 3 text :&lt;/p&gt;\\n&lt;ul&gt;\\n&lt;li&gt;Simple test ...</td>\n",
       "      <td>73155978</td>\n",
       "      <td>21</td>\n",
       "      <td>php|regex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;If you want to match the square brackets, y...</td>\n",
       "      <td>Grouping character strings</td>\n",
       "      <td>I have 3 text :\\n\\nSimple test 1 [https://www....</td>\n",
       "      <td>If you want to match the square brackets, you ...</td>\n",
       "      <td>To achieve the desired grouping, you can use t...</td>\n",
       "      <td>To achieve the desired grouping, you can use t...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254120</td>\n",
       "      <td>71900912</td>\n",
       "      <td>Convert array from spreadsheet into associativ...</td>\n",
       "      <td>&lt;p&gt;I've been having difficulty visualizing how...</td>\n",
       "      <td>71901148</td>\n",
       "      <td>96</td>\n",
       "      <td>php|arrays|multidimensional-array</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;This is a common issue with spreadsheets an...</td>\n",
       "      <td>Convert array from spreadsheet into associativ...</td>\n",
       "      <td>I've been having difficulty visualizing how to...</td>\n",
       "      <td>This is a common issue with spreadsheets and C...</td>\n",
       "      <td>Yes, the `array_combine` function can be used ...</td>\n",
       "      <td>Yes, the `array_combine` function can be used ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361337</td>\n",
       "      <td>71269489</td>\n",
       "      <td>ID components may not include unresolved token...</td>\n",
       "      <td>&lt;p&gt;I am trying to use a CfnParameter in the AW...</td>\n",
       "      <td>71313692</td>\n",
       "      <td>1213</td>\n",
       "      <td>python|amazon-web-services|amazon-cloudformati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;Managed to resolve by using --context inste...</td>\n",
       "      <td>ID components may not include unresolved token...</td>\n",
       "      <td>I am trying to use a CfnParameter in the AWS P...</td>\n",
       "      <td>Managed to resolve by using --context instead ...</td>\n",
       "      <td>The error message suggests that you are trying...</td>\n",
       "      <td>The error message suggests that you are trying...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        id                                              title  \\\n",
       "0  196461  71067715  CRA error. Html Webpack Plugin: Error: Child c...   \n",
       "1  243249  71098325  Hyperledger Fabric | Orderer PODs keeps restar...   \n",
       "2  375295  73155785                         Grouping character strings   \n",
       "3  254120  71900912  Convert array from spreadsheet into associativ...   \n",
       "4  361337  71269489  ID components may not include unresolved token...   \n",
       "\n",
       "                                                body  accepted_answer_id  \\\n",
       "0  <p>I create a default react app with <code>npx...            71086154   \n",
       "1  <p>I'm running Hyperledger Fabric network in A...            71168925   \n",
       "2  <p>I have 3 text :</p>\\n<ul>\\n<li>Simple test ...            73155978   \n",
       "3  <p>I've been having difficulty visualizing how...            71901148   \n",
       "4  <p>I am trying to use a CfnParameter in the AW...            71313692   \n",
       "\n",
       "   view_count                                               tags  \\\n",
       "0         221           node.js|reactjs|webpack|create-react-app   \n",
       "1         239           azure|kubernetes|hyperledger-fabric|raft   \n",
       "2          21                                          php|regex   \n",
       "3          96                  php|arrays|multidimensional-array   \n",
       "4        1213  python|amazon-web-services|amazon-cloudformati...   \n",
       "\n",
       "   answer_count  question_score  answer_score  \\\n",
       "0             1               0             0   \n",
       "1             1               0             0   \n",
       "2             1               0             2   \n",
       "3             1               0             1   \n",
       "4             1               0             1   \n",
       "\n",
       "                                stackoverflow_answer  \\\n",
       "0  <p>Solution: install <strong>react-scripts@4.0...   \n",
       "1  <p>Turns out my WAL logs directory was deleted...   \n",
       "2  <p>If you want to match the square brackets, y...   \n",
       "3  <p>This is a common issue with spreadsheets an...   \n",
       "4  <p>Managed to resolve by using --context inste...   \n",
       "\n",
       "                                      stripped_title  \\\n",
       "0  CRA error. Html Webpack Plugin: Error: Child c...   \n",
       "1  Hyperledger Fabric | Orderer PODs keeps restar...   \n",
       "2                         Grouping character strings   \n",
       "3  Convert array from spreadsheet into associativ...   \n",
       "4  ID components may not include unresolved token...   \n",
       "\n",
       "                                       stripped_body  \\\n",
       "0  I create a default react app with npx create-r...   \n",
       "1  I'm running Hyperledger Fabric network in Azur...   \n",
       "2  I have 3 text :\\n\\nSimple test 1 [https://www....   \n",
       "3  I've been having difficulty visualizing how to...   \n",
       "4  I am trying to use a CfnParameter in the AWS P...   \n",
       "\n",
       "                       stripped_stackoverflow_answer  \\\n",
       "0  Solution: install react-scripts@4.0.3. If you ...   \n",
       "1  Turns out my WAL logs directory was deleted. A...   \n",
       "2  If you want to match the square brackets, you ...   \n",
       "3  This is a common issue with spreadsheets and C...   \n",
       "4  Managed to resolve by using --context instead ...   \n",
       "\n",
       "                            gpt-3.5-turbo-16k_answer  \\\n",
       "0  It seems like you are encountering an error re...   \n",
       "1  The error message suggests that the raft log o...   \n",
       "2  To achieve the desired grouping, you can use t...   \n",
       "3  Yes, the `array_combine` function can be used ...   \n",
       "4  The error message suggests that you are trying...   \n",
       "\n",
       "                   stripped_gpt-3.5-turbo-16k_answer eval_choice  \n",
       "0  It seems like you are encountering an error re...           A  \n",
       "1  The error message suggests that the raft log o...           C  \n",
       "2  To achieve the desired grouping, you can use t...           A  \n",
       "3  Yes, the `array_combine` function can be used ...           A  \n",
       "4  The error message suggests that you are trying...           B  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obed's answer reading code\n",
    "#   (because by his evaluation, the metric disagrees with the written response ~10% of the time)\n",
    "import re\n",
    "def get_answer_from_response(text):\n",
    "    \"\"\"Parses the output text for the evaluation choice.\"\"\"\n",
    "    \n",
    "    last_letter = text[-1]\n",
    "    if last_letter not in ['A', 'B', 'C', 'D', 'E']:\n",
    "        matches = re.findall('\\((.*?)\\)', text)\n",
    "        return matches[-1] if matches else None      \n",
    "    return last_letter\n",
    "\n",
    "\n",
    "# Iterate through our evals results\n",
    "for index, chunk in enumerate(wd_list):\n",
    "\n",
    "    # Update our record path each iteration\n",
    "    record_path = record_paths[index]\n",
    "\n",
    "    # Empty lists for us to store stuff in, to later add to the chunk's dataframe\n",
    "    answer_list = []\n",
    "    provided_answer_list = []\n",
    "    sampled_list = []\n",
    "    metric_list = []\n",
    "\n",
    "    # Open the record (.jsonl) for this iteration\n",
    "    with open(record_path) as f:\n",
    "        # Skip the first two lines (they're just metadata about the query and response)\n",
    "        for _ in range(2):\n",
    "            next(f)\n",
    "\n",
    "        # Iterate through the rest of the file line-by-line\n",
    "        for line in f:\n",
    "            eval_line = json.loads(line)\n",
    "\n",
    "            # process the \"sampling\" half of each evaluation response\n",
    "            if eval_line[\"type\"] == \"sampling\":\n",
    "\n",
    "                # Extract the response from the answer received\n",
    "                answer = eval_line[\"data\"][\"sampled\"][0]\n",
    "                extr_choice = get_answer_from_response(answer)\n",
    "\n",
    "                # Add the extracted response and the raw response to our lists\n",
    "                answer_list.append(extr_choice)\n",
    "                sampled_list.append(eval_line)\n",
    "\n",
    "            # Process the \"metric\" half of each evaluation response\n",
    "            elif eval_line[\"type\"] == \"metric\":\n",
    "\n",
    "                # Also pull evals' self-reported response\n",
    "                og_choice = eval_line[\"data\"][\"choice\"]\n",
    "\n",
    "                # Add that and the raw response to our lists\n",
    "                provided_answer_list.append(og_choice)\n",
    "                metric_list.append(eval_line)\n",
    "\n",
    "    # Add the populated lists into our chunk's dataframe\n",
    "    chunk[\"original_eval_choice\"] = provided_answer_list\n",
    "    chunk[\"extracted_eval_choice\"] = answer_list\n",
    "    chunk[\"eval_full_sampled\"] = sampled_list\n",
    "    chunk[\"eval_full_metric\"] = metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine each of the chunked dataframes, export to CSV\n",
    "combined = pd.concat(wd_list)\n",
    "combined.to_csv(\"dataset_results.csv\")\n",
    "\n",
    "# Preview the result\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE TOKEN ESTIMATION IS STILL BEING INTEGRATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "# temp 2023-09-27\n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "text = \"\\n\\nCompare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.\\nThe submitted answer may either be a subset or superset of the expert answer, or it may conflict with it. Determine which case applies. Answer the question by selecting one of the following options:\\n(A) The submitted answer is a subset of the expert answer and is fully consistent with it.\\n(B) The submitted answer is a superset of the expert answer and is fully consistent with it.\\n(C) The submitted answer contains all the same details as the expert answer.\\n(D) There is a disagreement between the submitted answer and the expert answer.\\n(E) The answers differ, but these differences don't matter from the perspective of factuality.\\n\\nFirst, write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset. Then print only a single choice from \\\"A\\\" or \\\"B\\\" or \\\"C\\\" or \\\"D\\\" or \\\"E\\\" (without quotes or punctuation) on its own line corresponding to the correct answer. At the end, repeat just the answer by itself on a new line.\\n\\nReasoning:\"\n",
    "\n",
    "tokens = len(encoding.encode(text, disallowed_special=()))\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511 over 3000 tokens in 100000 samples\n",
      "328 over 6000 tokens in 100000 samples\n",
      "59 over 12000 tokens in 100000 samples\n"
     ]
    }
   ],
   "source": [
    "# temp thing for token estimation TODO: update and incorporate into main thing\n",
    "\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "samples = 100000\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "ans_tokens = 0\n",
    "que_tokens = 0\n",
    "row_tokens = 0\n",
    "rows_over_3k = 0\n",
    "rows_over_6k = 0\n",
    "rows_over_12k = 0\n",
    "\n",
    "for idx, row in wd.iterrows():\n",
    "    ans_tokens = len(encoding.encode(row[\"stripped_title\"], disallowed_special=()) + encoding.encode(row[\"stripped_body\"], disallowed_special=()))\n",
    "    que_tokens = len(encoding.encode(row[\"stripped_stackoverflow_answer\"], disallowed_special=()))\n",
    "    row_tokens = ans_tokens + que_tokens\n",
    "    if row_tokens > 3000:\n",
    "        rows_over_3k += 1\n",
    "    if row_tokens > 6000:\n",
    "        rows_over_6k += 1\n",
    "    if row_tokens > 12000:\n",
    "        rows_over_12k += 1\n",
    "\n",
    "print(rows_over_3k, f\"over 3000 tokens in {samples} samples\")\n",
    "print(rows_over_6k, f\"over 6000 tokens in {samples} samples\")\n",
    "print(rows_over_12k, f\"over 12000 tokens in {samples} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obed's token counter (unmodified code)\n",
    "import json\n",
    "import tiktoken\n",
    "import pprint\n",
    "\n",
    "tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "INPUT_COST_PER_1K = 0.0015\n",
    "OUTPUT_COST_PER_1K = 0.002\n",
    "jsonl_list = [\n",
    "    \"29_08_2023_jsonl/bioasq_3_gpt-3.5-turbo.jsonl\",\n",
    "]\n",
    "\n",
    "total_prompt_tokens = 0\n",
    "total_completion_tokens = 0\n",
    "for jsonl in jsonl_list:\n",
    "    with open(jsonl) as f:\n",
    "        for line in f:\n",
    "            json_object = json.loads(line)\n",
    "            try:\n",
    "                prompt = json_object['data']['prompt'][0]['content']\n",
    "                completion = json_object['data']['sampled'][0]\n",
    "            except:\n",
    "                continue\n",
    "            total_prompt_tokens += len(encoding.encode(prompt))\n",
    "            total_completion_tokens += len(encoding.encode(completion))\n",
    "        print(f\"Total prompt tokens so far: {total_prompt_tokens}\")\n",
    "        print(f\"Total completion tokens so far: {total_completion_tokens}\\n\")\n",
    "\n",
    "    \n",
    "total_prompt_cost = (total_prompt_tokens / 1000) * INPUT_COST_PER_1K\n",
    "total_completion_cost = (total_completion_tokens / 1000) * OUTPUT_COST_PER_1K\n",
    "total_cost = total_prompt_cost + total_completion_cost\n",
    "\n",
    "print(f\"Total tokens: {total_prompt_tokens + total_completion_tokens}\")\n",
    "print(f\"Total cost: {total_cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
